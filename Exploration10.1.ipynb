{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef41d9b3",
   "metadata": {},
   "source": [
    "# 라이브러리 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9d1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e696dfd",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f196cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161239</th>\n",
       "      <td>You're too suspicious about everything.</td>\n",
       "      <td>Vous êtes trop suspicieuses de tout.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114040</th>\n",
       "      <td>What do you know about pandas?</td>\n",
       "      <td>Que savez-vous des pandas ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119422</th>\n",
       "      <td>Thank you for your explanation.</td>\n",
       "      <td>Merci pour ton explication.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12768</th>\n",
       "      <td>You are strong.</td>\n",
       "      <td>Tu es forte.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175169</th>\n",
       "      <td>He received quite a few letters this morning.</td>\n",
       "      <td>Il a reçu pas mal de lettres, ce matin.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  eng  \\\n",
       "161239        You're too suspicious about everything.   \n",
       "114040                 What do you know about pandas?   \n",
       "119422                Thank you for your explanation.   \n",
       "12768                                 You are strong.   \n",
       "175169  He received quite a few letters this morning.   \n",
       "\n",
       "                                            fra  \\\n",
       "161239     Vous êtes trop suspicieuses de tout.   \n",
       "114040              Que savez-vous des pandas ?   \n",
       "119422              Merci pour ton explication.   \n",
       "12768                              Tu es forte.   \n",
       "175169  Il a reçu pas mal de lettres, ce matin.   \n",
       "\n",
       "                                                       cc  \n",
       "161239  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "114040  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "119422  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "12768   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "175169  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names = ['eng', 'fra', 'cc'], sep = '\\t')\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec853374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>We like Tom.</td>\n",
       "      <td>Nous aimons bien Tom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>I'd like a beer.</td>\n",
       "      <td>J'aimerais une bière.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12411</th>\n",
       "      <td>Try to do that.</td>\n",
       "      <td>Essaie de faire cela.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14953</th>\n",
       "      <td>Is it not black?</td>\n",
       "      <td>N'est-ce pas noir ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26615</th>\n",
       "      <td>Tom got kidnapped.</td>\n",
       "      <td>Tom a été kidnappé.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eng                    fra\n",
       "4150         We like Tom.  Nous aimons bien Tom.\n",
       "14639    I'd like a beer.  J'aimerais une bière.\n",
       "12411     Try to do that.  Essaie de faire cela.\n",
       "14953    Is it not black?    N'est-ce pas noir ?\n",
       "26615  Tom got kidnapped.    Tom a été kidnappé."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines [['eng', 'fra']][:33000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb0dcc7",
   "metadata": {},
   "source": [
    "문장 토큰화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929f27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = '<start>'\n",
    "eos_token = '<end>'\n",
    "\n",
    "def preprocess(lines, plus_token = True):\n",
    "    lines = lines.lower().strip()\n",
    "    \n",
    "    lines = re.sub(r\"([?.!,¿])\", r\" \\1 \", lines)\n",
    "    lines = re.sub(r'[\" \"]+', \" \", lines)\n",
    "    lines = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", lines)\n",
    "\n",
    "    lines = lines.strip()\n",
    "    if plus_token == True:\n",
    "        lines = '<start> ' + lines + ' <end>'    \n",
    "    lines = lines.split(' ')\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583cd17f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9135</th>\n",
       "      <td>[we, must, speak, .]</td>\n",
       "      <td>Il nous faut parler.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14115</th>\n",
       "      <td>[i, hate, my, voice, .]</td>\n",
       "      <td>Je déteste ma voix.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11423</th>\n",
       "      <td>[let, s, sit, down, .]</td>\n",
       "      <td>Asseyons-nous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>[we, re, busy, .]</td>\n",
       "      <td>Nous sommes occupées.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>[we, have, plans, .]</td>\n",
       "      <td>Nous avons des plans.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           eng                    fra\n",
       "9135      [we, must, speak, .]   Il nous faut parler.\n",
       "14115  [i, hate, my, voice, .]    Je déteste ma voix.\n",
       "11423   [let, s, sit, down, .]         Asseyons-nous.\n",
       "2620         [we, re, busy, .]  Nous sommes occupées.\n",
       "9118      [we, have, plans, .]  Nous avons des plans."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.eng = lines.eng.apply(lambda x: preprocess(x, plus_token = False))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a0fbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13973</th>\n",
       "      <td>[i, can, t, give, up, .]</td>\n",
       "      <td>[&lt;start&gt;, je, n, arrive, pas, arr, ter, ., &lt;end&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18886</th>\n",
       "      <td>[i, love, libraries, .]</td>\n",
       "      <td>[&lt;start&gt;, j, adore, les, biblioth, ques, ., &lt;e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>[go, away, !]</td>\n",
       "      <td>[&lt;start&gt;, bouge, !, &lt;end&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17293</th>\n",
       "      <td>[you, re, the, best, .]</td>\n",
       "      <td>[&lt;start&gt;, tu, es, le, meilleur, ., &lt;end&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>[i, feel, awful, .]</td>\n",
       "      <td>[&lt;start&gt;, je, me, sens, affreusement, mal, ., ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            eng  \\\n",
       "13973  [i, can, t, give, up, .]   \n",
       "18886   [i, love, libraries, .]   \n",
       "270               [go, away, !]   \n",
       "17293   [you, re, the, best, .]   \n",
       "4901        [i, feel, awful, .]   \n",
       "\n",
       "                                                     fra  \n",
       "13973  [<start>, je, n, arrive, pas, arr, ter, ., <end>]  \n",
       "18886  [<start>, j, adore, les, biblioth, ques, ., <e...  \n",
       "270                           [<start>, bouge, !, <end>]  \n",
       "17293          [<start>, tu, es, le, meilleur, ., <end>]  \n",
       "4901   [<start>, je, me, sens, affreusement, mal, ., ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.fra = lines.fra.apply(lambda x: preprocess(x))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2f58202",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokenizer = Tokenizer()\n",
    "eng_tokenizer.fit_on_texts(lines.eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b05d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_tokenizer = Tokenizer()\n",
    "fra_tokenizer.fit_on_texts(lines.fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b3ef676",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a94eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d7f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cf64853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수:  33000\n",
      "영어 단어장의 크기:  4672\n",
      "프랑스어 단어장의 크기:  7455\n",
      "영어 시퀸스의 최대 길이:  8\n",
      "프랑스어 시퀸스의 최대 길이:  17\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수: ', len(lines))\n",
    "print('영어 단어장의 크기: ', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기: ', fra_vocab_size)\n",
    "print('영어 시퀸스의 최대 길이: ', max_eng_seq_len)\n",
    "print('프랑스어 시퀸스의 최대 길이: ', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad53833",
   "metadata": {},
   "source": [
    "train data 와 test data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "908f052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71fdf66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding = 'post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding = 'post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c439671",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5839e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 8)\n",
      "(30000, 17)\n",
      "(30000, 17)\n",
      "(3000, 8)\n",
      "(3000, 17)\n",
      "(3000, 17)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91328c6",
   "metadata": {},
   "source": [
    "Model 설계 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53e6a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(eng_vocab_size, 256, input_length=max_eng_seq_len)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(units = 256, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac3c0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb = Embedding(fra_vocab_size, 256)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(dec_masking, initial_state = encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f81d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    1196032     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    1908480     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 256)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 256)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 525312      masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 7455)   1915935     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,071,071\n",
      "Trainable params: 6,071,071\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa0411a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58de6be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 23s 16ms/step - loss: 1.4679 - val_loss: 1.2130\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 1.1100 - val_loss: 1.0555\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.9841 - val_loss: 0.9726\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.8961 - val_loss: 0.9091\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.8328 - val_loss: 0.8717\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.7849 - val_loss: 0.8484\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.7467 - val_loss: 0.8289\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.7137 - val_loss: 0.8147\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.6894 - val_loss: 0.8115\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.6772 - val_loss: 0.8028\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.6528 - val_loss: 0.7993\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.6443 - val_loss: 0.8060\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.6368 - val_loss: 0.8036\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.6264 - val_loss: 0.8095\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.6229 - val_loss: 0.8144\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.6163 - val_loss: 0.8038\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5963 - val_loss: 0.8105\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5956 - val_loss: 0.8167\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5919 - val_loss: 0.8172\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5867 - val_loss: 0.8172\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5794 - val_loss: 0.8150\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5709 - val_loss: 0.8141\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5637 - val_loss: 0.8138\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5557 - val_loss: 0.8113\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5483 - val_loss: 0.8086\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5405 - val_loss: 0.8053\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5341 - val_loss: 0.8085\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5290 - val_loss: 0.8068\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5233 - val_loss: 0.8051\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5189 - val_loss: 0.8019\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5150 - val_loss: 0.8034\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5107 - val_loss: 0.8040\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5080 - val_loss: 0.8029\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5048 - val_loss: 0.8060\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5027 - val_loss: 0.8056\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5006 - val_loss: 0.8063\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4981 - val_loss: 0.8059\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4962 - val_loss: 0.8041\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4935 - val_loss: 0.8029\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4905 - val_loss: 0.8035\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4886 - val_loss: 0.8038\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4863 - val_loss: 0.8046\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4837 - val_loss: 0.7989\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4771 - val_loss: 0.7956\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4779 - val_loss: 0.8007\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4781 - val_loss: 0.8022\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4769 - val_loss: 0.8034\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4737 - val_loss: 0.8019\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4705 - val_loss: 0.8034\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4677 - val_loss: 0.8044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f95b3420d90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_train, decoder_input_train],decoder_target_train,\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 32, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038742b7",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0940533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 256)         1196032   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 525312    \n",
      "=================================================================\n",
      "Total params: 1,721,344\n",
      "Trainable params: 1,721,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0894ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = Embedding(fra_vocab_size, 256)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a1c107b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    1908480     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_2[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 7455)   1915935     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,349,727\n",
      "Trainable params: 4,349,727\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9103b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84c0f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f6a68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + idx2eng[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c94d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=fra2idx['<start>']) and i!=fra2idx['<end>']):\n",
    "            temp = temp + idx2fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f02fe49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: try it again . \n",
      "정답 문장: essaye encore . \n",
      "번역기가 번역한 문장:  essaie de . nouvea\n",
      "-----------------------------------\n",
      "입력 문장: my new car is red . \n",
      "정답 문장: ma nouvelle voiture est rouge . \n",
      "번역기가 번역한 문장:  ma ma ma la la l\n",
      "-----------------------------------\n",
      "입력 문장: tom became violent . \n",
      "정답 문장: tom est devenu violent . \n",
      "번역기가 번역한 문장:  tom tom tom tom \n",
      "-----------------------------------\n",
      "입력 문장: are you from here ? \n",
      "정답 문장: vous tes du coin ? \n",
      "번역기가 번역한 문장:  tu d vous tu ici ic\n",
      "-----------------------------------\n",
      "입력 문장: i m a fast learner . \n",
      "정답 문장: j apprends vite . \n",
      "번역기가 번역한 문장:  je je e e e . . \n"
     ]
    }
   ],
   "source": [
    "for seq_index in [1,100,301,777,2222]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
    "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8ed69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
